import requests
import socket

HTTP_Prefix = 'http://' #@Todo: use href also.
DOUBLE_QUOTE = '"'
FORWARD_SLASH = "/"


def host_matches(ip_list_known, ip_list_check):
	for ip_check in ip_list_check:
		if ip_check in ip_list_known:
			return True

	return False


def nslookup(host):
	ip_list = []
	ais = socket.getaddrinfo(host,0,0,0,0)
	for result in ais:
	  ip_list.append(result[-1][0])
	ip_list = list(set(ip_list))
	#print(ip_list)
	return ip_list

def append_if_not_exist(list, object):
	if object not in list:
		list.append(object)

	return list

def append_list_if_not_exist(list, list_to_append):
	for object in list_to_append:
		if object not in list:
			list.append(object)

	return list

def merge_form_dicts(higher, lower):
	for key in lower.keys():
		if key not in higher.keys():
			higher[key] = lower[key]

	return higher

def http_crawl(url, host, crawl_externally, previous_level_links = None):


	print("Requesting: " + url + ", Host: " + host)
	#Get address info of host
	host_ip_list = nslookup(host)

	#Request root, / and common CGI pages if root does not exist .. need outside helper to call
	#url = 'http://' + host + ':' + str(port)

	try:
		response = requests.get(url=url)  # using HTTP Requests for humans: http://docs.python-requests.org/en/latest/
		#print(response.text)
	except:
		print("Request failed. Service is not HTTP.")
		return None, None

	split_response = response.text.split(DOUBLE_QUOTE + HTTP_Prefix)
	#print(split_response)

	contains_form = False
	if "<input" in response.text:
		print("Page contains forms!")
		contains_form = True


	form_dict = {}
	form_dict[url] = contains_form

	links = []

	for segment in split_response[1:]:
		link = HTTP_Prefix + segment.split(DOUBLE_QUOTE)[0]
		#print(link)
		if (previous_level_links is None or link not in previous_level_links) and (link not in links):
			links.append(link)
			#print("Adding " + link)

	this_level_links = links.copy()
	if previous_level_links:
		this_level_links = this_level_links + previous_level_links.copy()

	this_level_links.append(url)
	print("Number of links: " + str(len(links)))


	valid_links = {}
	for link in links:
		#if link not in lower_level_links:
		link_host = link.split(HTTP_Prefix)[1].split(FORWARD_SLASH)[0]
		link_ip_list = nslookup(link_host)
		#print(link_host)
		if host_matches(host_ip_list, link_ip_list) or crawl_externally:
			valid_links[link] = link_host
			print("Adding " + link)


	lower_level_links = []

	#form_dict = valid_links.copy()
	#for link in form_dict.keys():

	#Find all links
	for link in valid_links.keys():
		#print("Crawling to: " + link)
		collected_links, collected_form_dict = http_crawl(link, valid_links[link], crawl_externally, this_level_links)
		append_list_if_not_exist(lower_level_links, collected_links)
		append_list_if_not_exist(this_level_links, collected_links)#make sure we don't visit the same page twice.
		form_dict = merge_form_dicts(form_dict, collected_form_dict)
	

	#Find any input forms
	#Make a dict of link, form boolean


	#for each link in links
		#sublist, forms = http_crawl

	#merge lists, forms

	#return list_of_links, forms

	#return links
	append_list_if_not_exist(lower_level_links, list(valid_links.keys()))
	return lower_level_links, form_dict



"""
['http://192.168.1.115/?feed=rss2&#038;author=1', 'http://192.168.1.115/wp-comments-post.php', 'http://192.168.1.115/?feed=rss2&#038;p=1', 'http://192.168.1.115/?feed=rss2&#038;cat=1', 'http://192.168.1.115/?feed=rss2&#038;page_id=2', 'http://192.168.1.115/wp-admin/', 'http://192.168.1.115/wp-login.php?action=lostpassword', 'http://192.168.1.115/?author=1', 'http://192.168.1.115/?p=1', 'http://192.168.1.115/?feed=comments-rss2', 'http://192.168.1.115/?p=1#comment-1', 'http://192.168.1.115/?p=1#comments', 'http://192.168.1.115/?cat=1', 'http://192.168.1.115/xmlrpc.php?rsd', 'http://192.168.1.115/?page_id=2', 'http://192.168.1.115/', 'http://192.168.1.115/wp-content/themes/twentythirteen/js/html5.js', 'http://192.168.1.115/?feed=rss2', 'http://192.168.1.115/wp-login.php', 'http://192.168.1.115/xmlrpc.php', 'http://192.168.1.115/wp-includes/wlwmanifest.xml']
['http://192.168.1.115/?feed=rss2&#038;p=1', 'http://192.168.1.115/wp-comments-post.php', 'http://192.168.1.115/?feed=rss2&#038;page_id=2', 'http://192.168.1.115/?feed=rss2&#038;author=1', 'http://192.168.1.115/wp-login.php?action=lostpassword', 'http://192.168.1.115/wp-admin/', 'http://192.168.1.115/?feed=rss2&#038;cat=1', 'http://192.168.1.115/wp-includes/wlwmanifest.xml', 'http://192.168.1.115/?p=1#comment-1', 'http://192.168.1.115/?page_id=2', 'http://192.168.1.115/?feed=comments-rss2', 'http://192.168.1.115/xmlrpc.php?rsd', 'http://192.168.1.115/wp-content/themes/twentythirteen/js/html5.js', 'http://192.168.1.115/?author=1', 'http://192.168.1.115/', 'http://192.168.1.115/wp-login.php', 'http://192.168.1.115/?feed=rss2', 'http://192.168.1.115/?p=1', 'http://192.168.1.115/?p=1#comments', 'http://192.168.1.115/xmlrpc.php', 'http://192.168.1.115/?cat=1']
['http://192.168.1.115/?feed=rss2&#038;cat=1', 'http://192.168.1.115/?feed=rss2&#038;p=1', 'http://192.168.1.115/wp-comments-post.php', 'http://192.168.1.115/wp-login.php?action=lostpassword', 'http://192.168.1.115/wp-admin/', 'http://192.168.1.115/?feed=rss2&#038;page_id=2', 'http://192.168.1.115/?feed=rss2&#038;author=1', 'http://192.168.1.115/?cat=1', 'http://192.168.1.115/?p=1', 'http://192.168.1.115/?feed=rss2', 'http://192.168.1.115/?p=1#comment-1', 'http://192.168.1.115/xmlrpc.php?rsd', 'http://192.168.1.115/wp-login.php', 'http://192.168.1.115/?feed=comments-rss2', 'http://192.168.1.115/?page_id=2', 'http://192.168.1.115/wp-content/themes/twentythirteen/js/html5.js', 'http://192.168.1.115/', 'http://192.168.1.115/xmlrpc.php', 'http://192.168.1.115/?p=1#comments', 'http://192.168.1.115/wp-includes/wlwmanifest.xml', 'http://192.168.1.115/?author=1']

"""